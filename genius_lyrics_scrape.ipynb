{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies \n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store filepaths in variables\n",
    "file_new = \"music_list_data/new_school.csv\"\n",
    "file_old = \"music_list_data/old_school.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read our data files with the pandas library\n",
    "new_df = pd.read_csv(file_new)\n",
    "old_df = pd.read_csv(file_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add new columns for reformatted data for \"new\" data\n",
    "new_df['artists'] = [(\"-\".join(row.split())) for row in new_df['artist']]\n",
    "new_df['songs'] = [(\"-\".join(row.split())) for row in new_df['song']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add new columns for reformatted data for \"old\" data\n",
    "old_df['artists'] = [(\"-\".join(row.split())) for row in old_df['artist']]\n",
    "old_df['songs'] = [(\"-\".join(row.split())) for row in old_df['song']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store nltk stop words in a variable\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# small_stop_words is a list of length 4 or less words in stop_words\n",
    "small_stop_words = [w for w in stop_words if len(w) < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genius_lyrics_scrape(artist_name, song_name):\n",
    "\n",
    "    # Define a empty list to store all scraped data \n",
    "    lyrics_result_list = []\n",
    "\n",
    "    with Browser() as browser:\n",
    "        url = 'https://genius.com/' + artist_name + '-' + song_name + '-lyrics' \n",
    "        browser.visit(url)\n",
    "        genius_html = browser.html\n",
    "        \n",
    "        # Create BeautifulSoup object; parse with 'html.parser'\n",
    "        soup = BeautifulSoup(genius_html, 'html.parser')\n",
    "\n",
    "        results = soup.find_all('div', class_ = 'lyrics')\n",
    "    \n",
    "    # Loop through returned results to collect the lyrics text\n",
    "    for result in results:\n",
    "        try:\n",
    "            # Retrieve the raw lyrics text\n",
    "            full_lyrics = result.find('br').get_text(separator=u' ')\n",
    "            # Clean up the raw lyrics to remove bracketed text and punctiations  \n",
    "            clean_lyrics = re.sub(\"[\\(\\[].*?[\\)\\]]\", \" \", full_lyrics)\n",
    "            words = clean_lyrics.lower().split()\n",
    "            clean_words = [''.join(c for c in s if c not in string.punctuation) for s in words]\n",
    "            # Determine number of unique words and the avg length of the unique words            \n",
    "            unique_words = set(clean_words)\n",
    "            avg_word_len = sum(map(len, unique_words))/len(unique_words)\n",
    "            # Use stopwords to remove common words \n",
    "            filter_words = list(filter(lambda w: not w in stop_words,unique_words))\n",
    "            filter_avg_word_len = sum(map(len, filter_words))/len(filter_words)\n",
    "            big_words = list(filter(lambda w: not w in small_stop_words,unique_words))\n",
    "            big_avg_word_len = sum(map(len, big_words))/len(big_words)\n",
    "\n",
    "        except:\n",
    "            print(\"This is an error message!\")\n",
    "\n",
    "    lyrics_result_list = [song_name, len(words), len(unique_words), len(filter_words), \n",
    "                          len(big_words), avg_word_len, filter_avg_word_len, big_avg_word_len]\n",
    "    return lyrics_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run \"old\" data through scrape function and store into a variable\n",
    "old_song_results_series = old_df.apply(lambda x: genius_lyrics_scrape(x['artists'],x['songs']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run \"new\" data through scrape function and store into a variable\n",
    "new_song_results_series = new_df.apply(lambda x: genius_lyrics_scrape(x['artists'],x['songs']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of \"old\" scraped data\n",
    "old_song_results_list = list(old_song_results_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of \"new\" scraped data\n",
    "new_song_results_list = list(new_song_results_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store header names into a variable\n",
    "headers = ['songs', '#_words', '#_unique_words', '#_filter_words', '#_big_words', 'avg_word_len', 'filter_avg_word_len', 'big_avg_word_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a data frame of \"old\" scraped data\n",
    "old_song_results = pd.DataFrame(old_song_results_list, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a data frame of \"new\" scraped data\n",
    "new_song_results = pd.DataFrame(new_song_results_list, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge \"old\" scraped data frame with original \"old\" data frame, and export to a csv\n",
    "old_results_df = old_df.merge(old_song_results, on='songs')\n",
    "old_results_df.to_csv('old_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge \"new\" scraped data frame with original \"new\" data frame, and export to a csv\n",
    "new_results_df = new_df.merge(new_song_results, on='songs')\n",
    "new_results_df.to_csv('new_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
